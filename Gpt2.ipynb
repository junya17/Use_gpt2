{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iakI2t4KkjH4",
        "outputId": "264e8bc7-eff5-4a7e-9055-19e980ed0235"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "What is the Earth like? It was formed from a spherical body with a few rocky cores. When the Sun went out of phase with space, the Earth went out of phase, too.\n",
            "\n",
            "Advertisement\n",
            "\n",
            "In a series of experiments and papers published over the years, it looks like our planet is not quite at its own technological optimum but in a state of extreme confusion.\n",
            "\n",
            "Researchers think that we're far from our ultimate equilibrium: the same, almost-pre-industrial, planet as\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "from transformers import GPT2Tokenizer, GPT2LMHeadModel\n",
        "\n",
        "# トークナイザーとモデルのロード\n",
        "tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\n",
        "model = GPT2LMHeadModel.from_pretrained('gpt2')\n",
        "\n",
        "# トークナイザーのpad_tokenを設定\n",
        "tokenizer.pad_token = tokenizer.eos_token\n",
        "\n",
        "# GPUが利用可能な場合はGPUにモデルを移動\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"gpu\"\n",
        "model.to(device)\n",
        "\n",
        "# 生成したいテキストのプロンプト\n",
        "input_text = \"What is the Earth like?\"\n",
        "# プロンプトをエンコードしてテンソルに変換し、attention_maskを生成\n",
        "inputs = tokenizer(input_text, return_tensors='pt', padding=True, truncation=True, max_length=512)\n",
        "\n",
        "# 入力テンソルをモデルと同じデバイスに移動\n",
        "inputs = {k: v.to(device) for k, v in inputs.items()}\n",
        "\n",
        "# テキスト生成の実行\n",
        "output_sequences = model.generate(\n",
        "    input_ids=inputs['input_ids'],\n",
        "    attention_mask=inputs['attention_mask'],\n",
        "    max_length=100,\n",
        "    temperature=1.0,\n",
        "    top_k=50,\n",
        "    top_p=0.95,\n",
        "    pad_token_id=tokenizer.eos_token_id,\n",
        "    do_sample=True,\n",
        "    num_return_sequences=1\n",
        ")\n",
        "\n",
        "# 生成されたテキストのデコード\n",
        "generated_text = tokenizer.decode(output_sequences[0], skip_special_tokens=True)\n",
        "\n",
        "print(generated_text)\n"
      ]
    }
  ]
}